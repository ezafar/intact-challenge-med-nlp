{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import model_selection, naive_bayes\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ.get(\"PROCESSED_DATA_PATH\")\n",
    "data = pd.read_csv(f\"{data_path}/simple_cleaned_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>labels</th>\n",
       "      <th>transcription_cleaned_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>REASON FOR THE VISIT:,  Very high PT/INR.,HIST...</td>\n",
       "      <td>0</td>\n",
       "      <td>reason visit high pt inr history patient year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...</td>\n",
       "      <td>1</td>\n",
       "      <td>preoperative diagnosis acetabular fracture lef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>NAME OF PROCEDURE,1.  Selective coronary angio...</td>\n",
       "      <td>1</td>\n",
       "      <td>name procedure selective coronary angiography ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radiology</td>\n",
       "      <td>REFERRING DIAGNOSIS: , Motor neuron disease.,P...</td>\n",
       "      <td>2</td>\n",
       "      <td>referring diagnosis motor neuron disease perti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>CHIEF COMPLAINT: , Dental pain.,HISTORY OF PRE...</td>\n",
       "      <td>0</td>\n",
       "      <td>chief complaint dental pain history present il...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         medical_specialty                                      transcription  \\\n",
       "0   Emergency Room Reports  REASON FOR THE VISIT:,  Very high PT/INR.,HIST...   \n",
       "1                  Surgery  PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...   \n",
       "2                  Surgery  NAME OF PROCEDURE,1.  Selective coronary angio...   \n",
       "3                Radiology  REFERRING DIAGNOSIS: , Motor neuron disease.,P...   \n",
       "4   Emergency Room Reports  CHIEF COMPLAINT: , Dental pain.,HISTORY OF PRE...   \n",
       "\n",
       "   labels                       transcription_cleaned_simple  \n",
       "0       0  reason visit high pt inr history patient year ...  \n",
       "1       1  preoperative diagnosis acetabular fracture lef...  \n",
       "2       1  name procedure selective coronary angiography ...  \n",
       "3       2  referring diagnosis motor neuron disease perti...  \n",
       "4       0  chief complaint dental pain history present il...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['transcription_cleaned_simple'], data['labels'], test_size=0.2, random_state=42, stratify=data['labels'])\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1 scores: [0.07987754 0.07580094 0.07729746]\n",
      "Average F1 score: 0.07765864456475817\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        13\n",
      "           1       0.35      0.58      0.44       173\n",
      "           2       0.28      0.30      0.29        43\n",
      "           3       1.00      0.00      0.00         7\n",
      "           4       0.17      0.12      0.14        34\n",
      "           5       0.16      0.09      0.11        35\n",
      "           6       0.21      0.21      0.21        58\n",
      "           7       0.30      0.29      0.29        62\n",
      "           8       1.00      0.00      0.00        13\n",
      "           9       0.00      0.00      0.00        16\n",
      "          10       0.25      0.12      0.16        42\n",
      "          11       1.00      0.00      0.00        14\n",
      "          12       1.00      0.00      0.00         4\n",
      "          13       0.18      0.15      0.16        27\n",
      "          14       1.00      0.00      0.00         2\n",
      "          15       1.00      0.00      0.00         9\n",
      "          16       0.29      0.68      0.41        82\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        14\n",
      "          19       0.25      0.16      0.20        25\n",
      "          20       0.18      0.11      0.14        27\n",
      "          21       0.33      0.29      0.31        17\n",
      "          22       1.00      0.00      0.00         1\n",
      "          23       1.00      0.00      0.00         4\n",
      "          24       1.00      0.00      0.00         4\n",
      "          25       1.00      0.00      0.00         8\n",
      "          26       1.00      0.00      0.00         1\n",
      "          27       0.50      0.15      0.24        13\n",
      "          28       1.00      0.00      0.00         2\n",
      "          29       1.00      0.00      0.00         4\n",
      "          30       1.00      0.00      0.00        11\n",
      "          31       1.00      0.00      0.00         3\n",
      "          32       1.00      0.00      0.00         3\n",
      "          33       1.00      0.00      0.00         3\n",
      "          34       0.43      0.27      0.33        11\n",
      "          35       1.00      0.00      0.00         2\n",
      "          36       1.00      0.00      0.00         1\n",
      "          37       1.00      0.00      0.00         2\n",
      "          38       1.00      0.00      0.00         2\n",
      "          39       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.29       794\n",
      "   macro avg       0.70      0.09      0.09       794\n",
      "weighted avg       0.37      0.29      0.24       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the base logistic regression model\n",
    "base_logistic_pipeline = Pipeline(\n",
    "    [(\"tfidf\", TfidfVectorizer()), (\"clf\", LogisticRegression())]\n",
    ")\n",
    "\n",
    "# Evaluate using cross-validation \n",
    "f1_scores = cross_val_score(\n",
    "    base_logistic_pipeline, X_train, y_train, cv=cv, scoring=\"f1_macro\"\n",
    ")\n",
    "\n",
    "print(\"Cross-validated F1 scores:\", f1_scores)\n",
    "print(\"Average F1 score:\", f1_scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "# Train the model on the full training data and evaluate on the test set\n",
    "base_logistic_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = base_logistic_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# Test Set Evaluate\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TF-IDF Vectorizer + Naive Bayes ---\n",
      "Cross-validated F1 scores: [0.0482423  0.04867372 0.0510881 ]\n",
      "Average F1 score: 0.04933470622565611\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        13\n",
      "           1       0.41      0.90      0.56       173\n",
      "           2       0.25      0.14      0.18        43\n",
      "           3       1.00      0.00      0.00         7\n",
      "           4       0.36      0.26      0.31        34\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.17      0.05      0.08        58\n",
      "           7       0.37      0.24      0.29        62\n",
      "           8       1.00      0.00      0.00        13\n",
      "           9       1.00      0.00      0.00        16\n",
      "          10       1.00      0.00      0.00        42\n",
      "          11       1.00      0.00      0.00        14\n",
      "          12       1.00      0.00      0.00         4\n",
      "          13       0.00      0.00      0.00        27\n",
      "          14       1.00      0.00      0.00         2\n",
      "          15       1.00      0.00      0.00         9\n",
      "          16       0.25      0.90      0.40        82\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       1.00      0.00      0.00        14\n",
      "          19       0.33      0.08      0.13        25\n",
      "          20       1.00      0.00      0.00        27\n",
      "          21       1.00      0.00      0.00        17\n",
      "          22       1.00      0.00      0.00         1\n",
      "          23       1.00      0.00      0.00         4\n",
      "          24       1.00      0.00      0.00         4\n",
      "          25       1.00      0.00      0.00         8\n",
      "          26       1.00      0.00      0.00         1\n",
      "          27       1.00      0.00      0.00        13\n",
      "          28       1.00      0.00      0.00         2\n",
      "          29       1.00      0.00      0.00         4\n",
      "          30       1.00      0.00      0.00        11\n",
      "          31       1.00      0.00      0.00         3\n",
      "          32       1.00      0.00      0.00         3\n",
      "          33       1.00      0.00      0.00         3\n",
      "          34       1.00      0.00      0.00        11\n",
      "          35       1.00      0.00      0.00         2\n",
      "          36       1.00      0.00      0.00         1\n",
      "          37       1.00      0.00      0.00         2\n",
      "          38       1.00      0.00      0.00         2\n",
      "          39       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33       794\n",
      "   macro avg       0.83      0.06      0.05       794\n",
      "weighted avg       0.52      0.33      0.22       794\n",
      "\n",
      "\n",
      "--- Count Vectorizer + Naive Bayes ---\n",
      "Cross-validated F1 scores: [0.17986148 0.19375036 0.18328296]\n",
      "Average F1 score: 0.18563159959545664\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.33      0.16      0.21       173\n",
      "           2       0.29      0.33      0.31        43\n",
      "           3       0.30      0.43      0.35         7\n",
      "           4       0.18      0.15      0.16        34\n",
      "           5       0.40      0.51      0.45        35\n",
      "           6       0.44      0.48      0.46        58\n",
      "           7       0.35      0.32      0.34        62\n",
      "           8       0.20      0.08      0.11        13\n",
      "           9       0.39      0.56      0.46        16\n",
      "          10       0.18      0.26      0.22        42\n",
      "          11       0.00      0.00      0.00        14\n",
      "          12       0.20      0.25      0.22         4\n",
      "          13       0.08      0.07      0.08        27\n",
      "          14       0.25      0.50      0.33         2\n",
      "          15       0.58      0.78      0.67         9\n",
      "          16       0.26      0.41      0.32        82\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       0.30      0.57      0.39        14\n",
      "          19       0.38      0.68      0.49        25\n",
      "          20       0.37      0.41      0.39        27\n",
      "          21       0.27      0.24      0.25        17\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       1.00      0.00      0.00         4\n",
      "          24       0.00      0.00      0.00         4\n",
      "          25       0.67      0.25      0.36         8\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.53      0.62      0.57        13\n",
      "          28       0.33      0.50      0.40         2\n",
      "          29       0.43      0.75      0.55         4\n",
      "          30       0.00      0.00      0.00        11\n",
      "          31       0.00      0.00      0.00         3\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.00      0.00      0.00         3\n",
      "          34       0.58      0.64      0.61        11\n",
      "          35       0.33      0.50      0.40         2\n",
      "          36       1.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31       794\n",
      "   macro avg       0.34      0.29      0.25       794\n",
      "weighted avg       0.31      0.31      0.29       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Define vectorizers to compare\n",
    "vectorizers = {\n",
    "    \"TF-IDF\": TfidfVectorizer(max_features=10000),\n",
    "    \"Count\": CountVectorizer()\n",
    "}\n",
    "\n",
    "for name, vectorizer in vectorizers.items():\n",
    "    print(f\"\\n--- {name} Vectorizer + Naive Bayes ---\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"clf\", MultinomialNB(alpha=0.5))\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation F1 scores\n",
    "    f1_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1_macro\")\n",
    "    print(\"Cross-validated F1 scores:\", f1_scores)\n",
    "    print(\"Average F1 score:\", f1_scores.mean())\n",
    "    \n",
    "    # Fit and evaluate on the test set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    print(\"Test Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1 scores: [0.00892164 0.00892857 0.00892857]\n",
      "Average F1 score: 0.008926262514315268\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        13\n",
      "           1       0.22      1.00      0.36       173\n",
      "           2       1.00      0.00      0.00        43\n",
      "           3       1.00      0.00      0.00         7\n",
      "           4       1.00      0.00      0.00        34\n",
      "           5       1.00      0.00      0.00        35\n",
      "           6       1.00      0.00      0.00        58\n",
      "           7       1.00      0.00      0.00        62\n",
      "           8       1.00      0.00      0.00        13\n",
      "           9       1.00      0.00      0.00        16\n",
      "          10       1.00      0.00      0.00        42\n",
      "          11       1.00      0.00      0.00        14\n",
      "          12       1.00      0.00      0.00         4\n",
      "          13       1.00      0.00      0.00        27\n",
      "          14       1.00      0.00      0.00         2\n",
      "          15       1.00      0.00      0.00         9\n",
      "          16       1.00      0.00      0.00        82\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       1.00      0.00      0.00        14\n",
      "          19       1.00      0.00      0.00        25\n",
      "          20       1.00      0.00      0.00        27\n",
      "          21       1.00      0.00      0.00        17\n",
      "          22       1.00      0.00      0.00         1\n",
      "          23       1.00      0.00      0.00         4\n",
      "          24       1.00      0.00      0.00         4\n",
      "          25       1.00      0.00      0.00         8\n",
      "          26       1.00      0.00      0.00         1\n",
      "          27       1.00      0.00      0.00        13\n",
      "          28       1.00      0.00      0.00         2\n",
      "          29       1.00      0.00      0.00         4\n",
      "          30       1.00      0.00      0.00        11\n",
      "          31       1.00      0.00      0.00         3\n",
      "          32       1.00      0.00      0.00         3\n",
      "          33       1.00      0.00      0.00         3\n",
      "          34       1.00      0.00      0.00        11\n",
      "          35       1.00      0.00      0.00         2\n",
      "          36       1.00      0.00      0.00         1\n",
      "          37       1.00      0.00      0.00         2\n",
      "          38       1.00      0.00      0.00         2\n",
      "          39       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22       794\n",
      "   macro avg       0.98      0.03      0.01       794\n",
      "weighted avg       0.83      0.22      0.08       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base SVM Model\n",
    "base_svm_pipeline = Pipeline(\n",
    "    [(\"tfidf\", TfidfVectorizer()), (\"clf\", SVC(C=1.0, kernel=\"rbf\", gamma=\"auto\"))]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "f1_scores = cross_val_score(\n",
    "    base_svm_pipeline, X_train, y_train, cv=cv, scoring=\"f1_macro\"\n",
    ")\n",
    "\n",
    "print(\"Cross-validated F1 scores:\", f1_scores)\n",
    "print(\"Average F1 score:\", f1_scores.mean())\n",
    "\n",
    "\n",
    "# Train the model on the full training data and evaluate on the test set\n",
    "base_svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = base_svm_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# Test Set Evaluate\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
