{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Settings\n",
    "load_dotenv()\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ.get(\"PROCESSED_DATA_PATH\")\n",
    "data = pd.read_csv(f\"{data_path}/simple_cleaned_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>labels</th>\n",
       "      <th>transcription_cleaned_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>REASON FOR THE VISIT:,  Very high PT/INR.,HIST...</td>\n",
       "      <td>0</td>\n",
       "      <td>reason visit high pt inr history patient year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...</td>\n",
       "      <td>1</td>\n",
       "      <td>preoperative diagnosis acetabular fracture lef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>NAME OF PROCEDURE,1.  Selective coronary angio...</td>\n",
       "      <td>1</td>\n",
       "      <td>name procedure selective coronary angiography ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radiology</td>\n",
       "      <td>REFERRING DIAGNOSIS: , Motor neuron disease.,P...</td>\n",
       "      <td>2</td>\n",
       "      <td>referring diagnosis motor neuron disease perti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>CHIEF COMPLAINT: , Dental pain.,HISTORY OF PRE...</td>\n",
       "      <td>0</td>\n",
       "      <td>chief complaint dental pain history present il...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         medical_specialty                                      transcription  \\\n",
       "0   Emergency Room Reports  REASON FOR THE VISIT:,  Very high PT/INR.,HIST...   \n",
       "1                  Surgery  PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...   \n",
       "2                  Surgery  NAME OF PROCEDURE,1.  Selective coronary angio...   \n",
       "3                Radiology  REFERRING DIAGNOSIS: , Motor neuron disease.,P...   \n",
       "4   Emergency Room Reports  CHIEF COMPLAINT: , Dental pain.,HISTORY OF PRE...   \n",
       "\n",
       "   labels                       transcription_cleaned_simple  \n",
       "0       0  reason visit high pt inr history patient year ...  \n",
       "1       1  preoperative diagnosis acetabular fracture lef...  \n",
       "2       1  name procedure selective coronary angiography ...  \n",
       "3       2  referring diagnosis motor neuron disease perti...  \n",
       "4       0  chief complaint dental pain history present il...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['transcription_cleaned_simple'], data['labels'], test_size=0.2, random_state=42, stratify=data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Logistic Regression Model\n",
    "base_logistic_model = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LogisticRegression())])\n",
    "# Train the model\n",
    "base_logistic_model.fit(X_train, y_train)\n",
    "# Predict on the training set\n",
    "y_pred = base_logistic_model.predict(X_train)\n",
    "\n",
    "# Train Set Evaluate\n",
    "train_report = classification_report(y_train, y_pred, zero_division=1, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        13\n",
      "           1       0.35      0.58      0.44       173\n",
      "           2       0.28      0.30      0.29        43\n",
      "           3       1.00      0.00      0.00         7\n",
      "           4       0.17      0.12      0.14        34\n",
      "           5       0.16      0.09      0.11        35\n",
      "           6       0.21      0.21      0.21        58\n",
      "           7       0.30      0.29      0.29        62\n",
      "           8       1.00      0.00      0.00        13\n",
      "           9       0.00      0.00      0.00        16\n",
      "          10       0.25      0.12      0.16        42\n",
      "          11       1.00      0.00      0.00        14\n",
      "          12       1.00      0.00      0.00         4\n",
      "          13       0.18      0.15      0.16        27\n",
      "          14       1.00      0.00      0.00         2\n",
      "          15       1.00      0.00      0.00         9\n",
      "          16       0.29      0.68      0.41        82\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        14\n",
      "          19       0.25      0.16      0.20        25\n",
      "          20       0.18      0.11      0.14        27\n",
      "          21       0.33      0.29      0.31        17\n",
      "          22       1.00      0.00      0.00         1\n",
      "          23       1.00      0.00      0.00         4\n",
      "          24       1.00      0.00      0.00         4\n",
      "          25       1.00      0.00      0.00         8\n",
      "          26       1.00      0.00      0.00         1\n",
      "          27       0.50      0.15      0.24        13\n",
      "          28       1.00      0.00      0.00         2\n",
      "          29       1.00      0.00      0.00         4\n",
      "          30       1.00      0.00      0.00        11\n",
      "          31       1.00      0.00      0.00         3\n",
      "          32       1.00      0.00      0.00         3\n",
      "          33       1.00      0.00      0.00         3\n",
      "          34       0.43      0.27      0.33        11\n",
      "          35       1.00      0.00      0.00         2\n",
      "          36       1.00      0.00      0.00         1\n",
      "          37       1.00      0.00      0.00         2\n",
      "          38       1.00      0.00      0.00         2\n",
      "          39       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.29       794\n",
      "   macro avg       0.70      0.09      0.09       794\n",
      "weighted avg       0.37      0.29      0.24       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_test_pred = base_logistic_model.predict(X_test)\n",
    "\n",
    "# Test Set Evaluate\n",
    "test_report = classification_report(y_test, y_test_pred, zero_division=1)\n",
    "print(test_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.04,\n",
       "  'f1-score': 0.07547169811320754,\n",
       "  'support': 50},\n",
       " '1': {'precision': 0.5063613231552163,\n",
       "  'recall': 0.8652173913043478,\n",
       "  'f1-score': 0.6388443017656501,\n",
       "  'support': 690},\n",
       " '2': {'precision': 0.5568181818181818,\n",
       "  'recall': 0.5764705882352941,\n",
       "  'f1-score': 0.5664739884393063,\n",
       "  'support': 170},\n",
       " '3': {'precision': 1.0,\n",
       "  'recall': 0.03571428571428571,\n",
       "  'f1-score': 0.0689655172413793,\n",
       "  'support': 28},\n",
       " '4': {'precision': 0.5555555555555556,\n",
       "  'recall': 0.5147058823529411,\n",
       "  'f1-score': 0.5343511450381679,\n",
       "  'support': 136},\n",
       " '5': {'precision': 0.7049180327868853,\n",
       "  'recall': 0.3049645390070922,\n",
       "  'f1-score': 0.42574257425742573,\n",
       "  'support': 141},\n",
       " '6': {'precision': 0.5281385281385281,\n",
       "  'recall': 0.5281385281385281,\n",
       "  'f1-score': 0.5281385281385281,\n",
       "  'support': 231},\n",
       " '7': {'precision': 0.5874439461883408,\n",
       "  'recall': 0.5303643724696356,\n",
       "  'f1-score': 0.5574468085106382,\n",
       "  'support': 247},\n",
       " '8': {'precision': 1.0,\n",
       "  'recall': 0.02,\n",
       "  'f1-score': 0.0392156862745098,\n",
       "  'support': 50},\n",
       " '9': {'precision': 0.6363636363636364,\n",
       "  'recall': 0.21212121212121213,\n",
       "  'f1-score': 0.3181818181818182,\n",
       "  'support': 66},\n",
       " '10': {'precision': 0.625,\n",
       "  'recall': 0.38922155688622756,\n",
       "  'f1-score': 0.4797047970479705,\n",
       "  'support': 167},\n",
       " '11': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.037037037037037035,\n",
       "  'f1-score': 0.07017543859649122,\n",
       "  'support': 54},\n",
       " '12': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15},\n",
       " '13': {'precision': 0.5625,\n",
       "  'recall': 0.5833333333333334,\n",
       "  'f1-score': 0.5727272727272726,\n",
       "  'support': 108},\n",
       " '14': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10},\n",
       " '15': {'precision': 0.75,\n",
       "  'recall': 0.16666666666666666,\n",
       "  'f1-score': 0.27272727272727276,\n",
       "  'support': 36},\n",
       " '16': {'precision': 0.41228070175438597,\n",
       "  'recall': 0.8597560975609756,\n",
       "  'f1-score': 0.5573122529644269,\n",
       "  'support': 328},\n",
       " '17': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5},\n",
       " '18': {'precision': 1.0,\n",
       "  'recall': 0.07017543859649122,\n",
       "  'f1-score': 0.13114754098360656,\n",
       "  'support': 57},\n",
       " '19': {'precision': 0.6578947368421053,\n",
       "  'recall': 0.25510204081632654,\n",
       "  'f1-score': 0.36764705882352944,\n",
       "  'support': 98},\n",
       " '20': {'precision': 0.6923076923076923,\n",
       "  'recall': 0.2523364485981308,\n",
       "  'f1-score': 0.3698630136986301,\n",
       "  'support': 107},\n",
       " '21': {'precision': 0.5111111111111111,\n",
       "  'recall': 0.6571428571428571,\n",
       "  'f1-score': 0.575,\n",
       "  'support': 70},\n",
       " '22': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6},\n",
       " '23': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17},\n",
       " '24': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15},\n",
       " '25': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30},\n",
       " '26': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4},\n",
       " '27': {'precision': 0.6060606060606061,\n",
       "  'recall': 0.37037037037037035,\n",
       "  'f1-score': 0.45977011494252873,\n",
       "  'support': 54},\n",
       " '28': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6},\n",
       " '29': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17},\n",
       " '30': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.045454545454545456,\n",
       "  'f1-score': 0.08510638297872342,\n",
       "  'support': 44},\n",
       " '31': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13},\n",
       " '32': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12},\n",
       " '33': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13},\n",
       " '34': {'precision': 0.75,\n",
       "  'recall': 0.5581395348837209,\n",
       "  'f1-score': 0.6399999999999999,\n",
       "  'support': 43},\n",
       " '35': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10},\n",
       " '36': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5},\n",
       " '37': {'precision': 1.0,\n",
       "  'recall': 0.2,\n",
       "  'f1-score': 0.33333333333333337,\n",
       "  'support': 10},\n",
       " '38': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7},\n",
       " '39': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5},\n",
       " 'accuracy': 0.518740157480315,\n",
       " 'macro avg': {'precision': 0.8160688513020562,\n",
       "  'recall': 0.2018108181672505,\n",
       "  'f1-score': 0.2166836636196104,\n",
       "  'support': 3175},\n",
       " 'weighted avg': {'precision': 0.6073768350890778,\n",
       "  'recall': 0.518740157480315,\n",
       "  'f1-score': 0.4659169939675087,\n",
       "  'support': 3175}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'base_logistic_model'.\n",
      "2025/02/10 00:32:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: base_logistic_model, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gentle-gnat-774 at: http://127.0.0.1:8080/#/experiments/0/runs/8c1a4a15596449dca169c85fc7dd2ab2\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'base_logistic_model'.\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow tracking\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    # For example, log parameters for the TfidfVectorizer and LogisticRegression\n",
    "    tfidf_params = base_logistic_model.named_steps['tfidf'].get_params()\n",
    "    mlflow.log_params(tfidf_params)\n",
    "    \n",
    "    clf_params = base_logistic_model.named_steps['clf'].get_params()\n",
    "    mlflow.log_params(clf_params)\n",
    "    \n",
    "    # Log metrics\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", train_report[\"accuracy\"])\n",
    "    mlflow.log_metric(\"macro_avg_score\", train_report[\"macro avg\"][\"f1-score\"])\n",
    "    mlflow.log_metric(\"macro_avg_precision\", train_report[\"macro avg\"][\"precision\"])\n",
    "    mlflow.log_metric(\"macro_avg_recall\", train_report[\"macro avg\"][\"recall\"])\n",
    "    mlflow.log_metric(\"weighted_avg_score\", train_report[\"weighted avg\"][\"f1-score\"])\n",
    "    mlflow.log_metric(\"weighted_avg_precision\", train_report[\"weighted avg\"][\"precision\"])\n",
    "    mlflow.log_metric(\"weighted_avg_recall\", train_report[\"weighted avg\"][\"recall\"])\n",
    "\n",
    "    # Convert X_train to DataFrame\n",
    "    X_train_df = X_train.to_frame()\n",
    "\n",
    "    # Log the model itself\n",
    "    signature = infer_signature(X_train_df, base_logistic_model.predict(X_train))\n",
    "    mlflow.sklearn.log_model(base_logistic_model, 'base_logistic_model', signature=signature, input_example=X_train_df, registered_model_name=\"base_logistic_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base SVM Model\n",
    "base_svm_model = Pipeline([('tfidf', TfidfVectorizer()), ('clf', svm.SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
